{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This program is written in python to scrape the table from 'www.nepalstock.com' which is a stock market of Nepal. This program only capture the daily transaction record of every company listed in the stock market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the needed library. We need requests to send the web request. We need csv to read and write the csv file, and finally we need BeautifulSoup to scrape the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we create a dictionary from list of company file we already had. Print funtion is just called to verify our dictioanry is as we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "reader = csv.reader(open('CompanyList.csv', 'r'))\n",
    "companyList = {}\n",
    "for row in reader:\n",
    "    k = row[1]\n",
    "    v = row[3]\n",
    "    companyList[k] = v\n",
    "print(companyList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These lines of code parse tables from the desired sites and finnally create a csv file associated with company name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_counter = 1   # This counter is used to skip the header of our dictionary.\n",
    "for key, value in companyList.items():\n",
    "    if dic_counter > 1:\n",
    "       \n",
    "        # url is dynamically created using a value from above dictionary. Dates are predetermined and can be custimezed. Limit 5000 is sufficient for our purpose.\n",
    "        \n",
    "        url = 'http://www.nepalstock.com/main/stockwiseprices/index/?startDate=2010-01-01&endDate=2020-05-03&stock-symbol={}&_limit=5000'.format(value)\n",
    "        print(url)\n",
    "        page = requests.get(url)\n",
    "        print(page.status_code)\n",
    "        \n",
    "        # file name is dynamically created using key from above dictionary.\n",
    "        \n",
    "        filename = '{}.csv'.format(key)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        my_table = soup.find('table', {'class': 'table table-condensed table-hover'})\n",
    "        table_rows = my_table.find_all('tr')\n",
    "        \n",
    "        count = 1  # Our scraped table had unnecessary data, to skip that we used a counter. \n",
    "        \n",
    "        # It write the desired value in desired file.csv\n",
    "        \n",
    "        with open(filename, 'a+') as f:\n",
    "            writer = csv.writer(f, delimiter=',', lineterminator='\\n', )\n",
    "            for tr in table_rows:\n",
    "                td = tr.find_all('td')\n",
    "                if count > 1:\n",
    "                    row = [i.text for i in td]\n",
    "                    writer.writerow(row)\n",
    "                    print(row)\n",
    "                count += 1\n",
    "    dic_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
